{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../..\")\n",
    "data_path = os.path.join(os.path.abspath(os.curdir), 'corpus', 'preprocessed')\n",
    "result_path = os.path.join(os.path.abspath(os.curdir),'models','LDA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading preprocessed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corpus = pd.read_pickle(os.path.join(data_path, 'corpus', 'corpus_preprocessed.pkl'))\n",
    "dictionary = corpora.Dictionary.load_from_text(os.path.join(data_path, 'dictionary', 'dictionary_preprocessed.txt'))\n",
    "texts = pd.read_pickle(os.path.join(data_path, 'lemmas', 'lemmatized_preprocessed.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def topic_search(result_path,\n",
    "                min_topics,\n",
    "                max_topics,\n",
    "                step_size_topics,\n",
    "                min_random,\n",
    "                max_random,\n",
    "                step_size_random,\n",
    "                chunksize,\n",
    "                passes):\n",
    "    '''\n",
    "    :param result_path: directory the search results are saved to\n",
    "    :param min_topics: min number of topics in the grid\n",
    "    :param max_topics: max number of topics in the grid\n",
    "    :param step_size_topics: step size between topics in the grid\n",
    "    :param min_random: lowest random value in the grid\n",
    "    :param max_random: highest random value in the grid\n",
    "    :param step_size_random: steps between random values considered\n",
    "    :param chunksize: number of documents to be used in each training chunk\n",
    "    :param passes: Nnumber of passes through the corpus during training\n",
    "    :return: a dataframe with the topic coherence for all models that are trained on based on the grids for num_topics and random_state\n",
    "    '''\n",
    "\n",
    "    #random parameter\n",
    "    random_range = range(min_random, max_random, step_size_random)\n",
    "\n",
    "    #topics parameter\n",
    "    topics_range = range(min_topics, max_topics, step_size_topics)\n",
    "\n",
    "    model_results = {'Random_State': [],\n",
    "                     'Topics': [],\n",
    "                     'Coherence': []\n",
    "                     }\n",
    "    pbar = tqdm(total= len(topics_range)*len(random_range))\n",
    "\n",
    "    for r in random_range:\n",
    "        for k in topics_range:\n",
    "            model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                               id2word=dictionary,\n",
    "                                               num_topics=k,\n",
    "                                               random_state=r,\n",
    "                                               chunksize=chunksize,\n",
    "                                               passes=passes,\n",
    "                                               eval_every=None)\n",
    "            coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "            model_results['Topics'].append(k)\n",
    "            model_results['Random_State'].append(r)\n",
    "            model_results['Coherence'].append(coherencemodel.get_coherence())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    model_results = pd.DataFrame.from_dict(model_results, orient='index').T\n",
    "\n",
    "    path = os.path.join(result_path, \"topic_search_results\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    file_name = os.path.join(path, \"topic_search_results.pkl\")\n",
    "    with open(file_name, 'wb') as handle:\n",
    "        pickle.dump(model_results, handle)\n",
    "\n",
    "\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topic_search(result_path=result_path,min_topics=1,max_topics=222,step_size_topics=10,min_random=1,max_random=100,step_size_random=20,chunksize=20000,passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_eta_search(result_path,\n",
    "                     num_topics,\n",
    "                     min_alpha,\n",
    "                     max_alpha,\n",
    "                     num_steps_alpha,\n",
    "                     min_beta,\n",
    "                     max_beta,\n",
    "                     num_steps_beta,\n",
    "                     random_state,\n",
    "                     chunksize,\n",
    "                     passes):\n",
    "    '''\n",
    "    :param result_path: directory the search results are saved to\n",
    "    :param num_topics: number of topics\n",
    "    :param min_alpha: lowest alpha value in the grid\n",
    "    :param max_alpha: highest alpha value in the grid\n",
    "    :param min_beta: lowest beta value in the grid\n",
    "    :param max_beta: highest beta value in the grid\n",
    "    :param chunksize: number of documents to be used in each training chunk\n",
    "    :param random_state: random state of the model\n",
    "    :param passes: number of passes through the corpus during training\n",
    "    :return: a dataframe with the topic coherence for all models that are trained on based on the grids for alpha and beta\n",
    "    '''\n",
    "\n",
    "    # define alpha grid\n",
    "    alpha = list(np.linspace(min_alpha, max_alpha, num_steps_alpha))\n",
    "    alpha = [round(elem, 5) for elem in alpha]\n",
    "\n",
    "    # define beta grid\n",
    "    beta = list(np.linspace(min_beta, max_beta, num_steps_beta))\n",
    "    beta = [round(elem, 5) for elem in beta]\n",
    "\n",
    "    # instantiate model results dictionary\n",
    "    model_results = {'Alpha': [],\n",
    "                     'Eta': [],\n",
    "                     'Coherence': []\n",
    "                     }\n",
    "\n",
    "    pbar = tqdm(total=(len(beta) * len(alpha)))\n",
    "    for a in alpha:\n",
    "        for b in beta:\n",
    "            model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                               id2word=dictionary,\n",
    "                                               num_topics=num_topics,\n",
    "                                               alpha=a,\n",
    "                                               beta=b,\n",
    "                                               random_state=random_state,\n",
    "                                               chunksize=chunksize,\n",
    "                                               passes=passes,\n",
    "                                               eval_every=None)\n",
    "            cv = CoherenceModel(model=model,\n",
    "                                texts=texts,\n",
    "                                dictionary=dictionary,\n",
    "                                coherence='c_v')\n",
    "            # Save the model results\n",
    "            model_results['Alpha'].append(a)\n",
    "            model_results['Beta'].append(b)\n",
    "            model_results['Coherence'].append(cv.get_coherence())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    model_results = pd.DataFrame.from_dict(model_results, orient='index').T\n",
    "\n",
    "    path = os.path.join(result_path, \"alpha_beta_search_results\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    file_name = os.path.join(path, \"alpha_beta_search_results.pkl\")\n",
    "    with open(file_name, 'wb') as handle:\n",
    "        pickle.dump(model_results, handle)\n",
    "\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train and save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_lda(corpus, id2word,num_topics,alpha,eta,chunksize,passes,random_state):\n",
    "    '''\n",
    "    :return: train a new LDA Model\n",
    "    '''\n",
    "    return gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                      id2word=id2word,\n",
    "                                      num_topics=num_topics,\n",
    "                                      alpha=alpha,\n",
    "                                      eta=eta,\n",
    "                                      chunksize=chunksize,\n",
    "                                      passes=passes,\n",
    "                                      random_state = random_state)\n",
    "\n",
    "lda = train_lda(corpus=corpus,id2word=dictionary,num_topics=31,random_state=41,alpha=0.45,eta=0.89,chunksize=20000,passes=15)\n",
    "lda.save(os.path.join(result_path,'model_results', 'lda.model'))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}