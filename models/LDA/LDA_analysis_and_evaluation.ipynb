{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import seaborn as sns\n",
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "os.chdir(\"../..\")\n",
    "data_path = os.path.join(os.path.abspath(os.curdir), 'corpus')\n",
    "result_path = os.path.join(os.path.abspath(os.curdir),'models','LDA')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading preprocessed files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:smart_open.smart_open_lib:{'uri': '/Users/florianlorisch/PycharmProjects/open-discourse-dynamic-topic-model/corpus/preprocessed/dictionary/dictionary_preprocessed.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'compression': None, 'transport_params': None}\n"
     ]
    }
   ],
   "source": [
    "corpus = pd.read_pickle(os.path.join(data_path,'preprocessed', 'corpus', 'corpus_preprocessed.pkl'))\n",
    "\n",
    "dictionary = corpora.Dictionary.load_from_text(os.path.join(data_path, 'preprocessed','dictionary', 'dictionary_preprocessed.txt'))\n",
    "\n",
    "texts = pd.read_pickle(os.path.join(data_path, 'preprocessed','lemmas', 'lemmatized_preprocessed.pkl'))\n",
    "\n",
    "speeches_df = pd.read_csv(os.path.join(data_path,'prepared', 'corpus.csv'))\n",
    "speeches_df.sort_values(by='id', ascending=True, inplace=True)\n",
    "speeches_df.drop(columns=speeches_df.columns[0],axis=1,inplace=True)\n",
    "speeches_df.reset_index(drop=True,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading modeling results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_num_topics_comparison = pd.read_pickle(\n",
    "    os.path.join(result_path, 'topic_search_results','num_topics_search_results.pkl'))\n",
    "results_alpha_eta_comparison = pd.read_pickle(\n",
    "    os.path.join(result_path, 'alpha_beta_search_results','alpha_beta_search_results.pkl'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading best performing LDA model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading LdaMulticore object from /Users/florianlorisch/PycharmProjects/open-discourse-dynamic-topic-model/models/LDA/model_results/lda.model\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': '/Users/florianlorisch/PycharmProjects/open-discourse-dynamic-topic-model/models/LDA/model_results/lda.model', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'compression': None, 'transport_params': None}\n",
      "INFO:gensim.utils:loading expElogbeta from /Users/florianlorisch/PycharmProjects/open-discourse-dynamic-topic-model/models/LDA/model_results/lda.model.expElogbeta.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute id2word to None\n",
      "INFO:gensim.utils:setting ignored attribute dispatcher to None\n",
      "INFO:gensim.utils:setting ignored attribute state to None\n",
      "INFO:gensim.utils:loaded /Users/florianlorisch/PycharmProjects/open-discourse-dynamic-topic-model/models/LDA/model_results/lda.model\n",
      "INFO:gensim.utils:loading LdaState object from /Users/florianlorisch/PycharmProjects/open-discourse-dynamic-topic-model/models/LDA/model_results/lda.model.state\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': '/Users/florianlorisch/PycharmProjects/open-discourse-dynamic-topic-model/models/LDA/model_results/lda.model.state', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'compression': None, 'transport_params': None}\n",
      "INFO:gensim.utils:loaded /Users/florianlorisch/PycharmProjects/open-discourse-dynamic-topic-model/models/LDA/model_results/lda.model.state\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': '/Users/florianlorisch/PycharmProjects/open-discourse-dynamic-topic-model/models/LDA/model_results/lda.model.id2word', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'compression': None, 'transport_params': None}\n"
     ]
    }
   ],
   "source": [
    "lda= gensim.models.LdaMulticore.load(os.path.join(result_path, 'model_results', 'lda.model'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quantitative evaluation of the best performing LDA with topic coherence (c_v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_coherence(model, texts, dictionary, coherence):\n",
    "    '''\n",
    "\n",
    "    :param model: best performing lda model\n",
    "    :param texts: tokenized texts\n",
    "    :param dictionary: Gensim dictionary mapping of id word to create corpus\n",
    "    :param coherence: specifies the coherence metric (e.g., c_v,c_uci','c_npmi')\n",
    "    :return: coherence score\n",
    "    '''\n",
    "    coherence=CoherenceModel(model=model,\n",
    "                   texts=texts,\n",
    "                   dictionary=dictionary,\n",
    "                   coherence=coherence).get_coherence()\n",
    "    print('Coherence Score: ', round(coherence, 4))\n",
    "    return coherence\n",
    "\n",
    "#function call\n",
    "get_coherence(model=lda, texts=texts, dictionary=dictionary, coherence='c_v')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quantitative evaluation of the best performing LDA with topic diversity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_list_of_topics(topicids,model,topn):\n",
    "    '''\n",
    "    :param topicids: id of topic that should be added to list\n",
    "    :param model: the model the topics are to be taken from\n",
    "    :param topn: number of top words that should be considered\n",
    "    :return: a list of list containing the topn words for selected topics\n",
    "\n",
    "    '''\n",
    "    topics_as_list = []\n",
    "    for topicid in topicids:\n",
    "        keywords = []\n",
    "        for keyword,_ in model.show_topic(topicid=topicid, topn=topn):\n",
    "            keywords.append(keyword)\n",
    "        topics_as_list.append(keywords)\n",
    "    return topics_as_list\n",
    "\n",
    "# function call\n",
    "topn=25\n",
    "model = lda\n",
    "topicids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]\n",
    "topic_list = get_list_of_topics(topicids=topicids,model=model,topn=topn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_topic_diversity(topics,topn):\n",
    "    '''\n",
    "\n",
    "    :param topics: list of list of topics as strings\n",
    "    :param topk: number of top words used to compute topic divcersity\n",
    "    :return: topic diversity score based on the top n words selected\n",
    "    '''\n",
    "    if topn > len(topics[0]):\n",
    "        raise Exception('not enough words for topn ' + str(topn))\n",
    "    else:\n",
    "        unique_words = set()\n",
    "        for topic in topics:\n",
    "            unique_words = unique_words.union(set(topic[:topn]))\n",
    "        td = len(unique_words) / (topn * len(topics))\n",
    "        return td\n",
    "\n",
    "\n",
    "get_topic_diversity(topics=topic_list, topn=25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Further analysis of the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def topic_to_dataframe(topicid, model, topn):\n",
    "    '''\n",
    "    :param topicids: id of topic that should be added to list\n",
    "    :param model: the model the topics are to be taken from\n",
    "    :param topn: number of top words that should be considered\n",
    "    :return: returns a dataframe with top n terms for the selected topic\n",
    "    '''\n",
    "\n",
    "    keywords = []\n",
    "\n",
    "    for keyword,probability in model.show_topic(topicid=topicid, topn=topn):\n",
    "        keywords.append((keyword,probability))\n",
    "    return pd.DataFrame(keywords)\n",
    "\n",
    "topic_df_5 = topic_to_dataframe(model=lda, topicid=5, topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def summary(model, topicids, topn=10):\n",
    "    '''\n",
    "\n",
    "    :param topicids: id of topic that should be added to list\n",
    "    :param model: the model the topics are to be taken from\n",
    "    :param topn: number of top words that should be considered\n",
    "    :return: a well formatted summary of all topics, containing the defined number of top words\n",
    "    '''\n",
    "    for topicid in topicids:\n",
    "        print('Topic %d' % topicid)\n",
    "        print(topic_to_dataframe(model=model, topicid=topicid, topn=topn))\n",
    "        print()\n",
    "\n",
    "\n",
    "# function call\n",
    "topicids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]\n",
    "\n",
    "summary(model=lda, topicids=topicids, topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_topic_probabilities(model,corpus,document_range):\n",
    "    '''\n",
    "\n",
    "    :param model: the model the topics are to be taken from\n",
    "    :param corpus: the corpus the model is trained with\n",
    "    :param document_range: the range of documents within the corpus that should be considered\n",
    "    :return: a dataframe with the topic probability distributions for all documents\n",
    "    '''\n",
    "    topic_documents = []\n",
    "    for document in document_range:\n",
    "        topic_distribution = model[corpus[document]]\n",
    "        topic_distribution = [tuple[1] for tuple in topic_distribution]\n",
    "        topic_documents.append(topic_distribution)\n",
    "    return topic_documents\n",
    "\n",
    "document_range = range(0,164869)\n",
    "topic_probabilities = get_topic_probabilities(model=lda,corpus=corpus, document_range=document_range)\n",
    "topic_probabilities_df = pd.DataFrame(topic_probabilities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_dominant_topics(data):\n",
    "    '''\n",
    "\n",
    "    :param data: dataframe with full topic distribution over all documents or timeslice\n",
    "    :return: dataframe with only the top topics for each document or timeslice\n",
    "    '''\n",
    "    top_topics = data.idxmax(axis = 1)\n",
    "    top_topics_share = data.max(axis = 1)\n",
    "    top_topics_df= pd.concat([top_topics, top_topics_share], axis=1)\n",
    "    top_topics_df.columns=['Top Topic', 'Topic Share']\n",
    "    return top_topics_df\n",
    "\n",
    "top_topics_df = get_dominant_topics(data=topic_probabilities_df)\n",
    "##%\n",
    "\n",
    "def get_speeches_top_topics(data, top_topics):\n",
    "    '''\n",
    "\n",
    "    :param data: dataframe containing the preprocessed speeches\n",
    "    :param top_topics: dataframe with top topics per speech\n",
    "    :return: Concenate dataframe with original speechcontent with top topics and top topic share per speech\n",
    "    '''\n",
    "    return pd.concat([data, top_topics], axis=1)\n",
    "\n",
    "speeches_with_topics = get_speeches_top_topics(data=speeches_df, top_topics=top_topics_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_topic_probabilities_over_time_steps(topic_probabilities):\n",
    "    '''\n",
    "\n",
    "    :param topic_probabilities: dataframe containing the topic probabilities for documents in a corpus\n",
    "    :return: dataframe containing the consolidated topic probabilities along time steps\n",
    "    '''\n",
    "    step_1 = pd.DataFrame(topic_probabilities.iloc[0:4444, :].sum()/4444).T\n",
    "    step_2 = pd.DataFrame(topic_probabilities.iloc[4444:8079, :].sum()/3635).T\n",
    "    step_3 = pd.DataFrame(topic_probabilities.iloc[8079:11335, :].sum()/3256).T\n",
    "    step_4 = pd.DataFrame(topic_probabilities.iloc[11335:16499, :].sum()/5164).T\n",
    "    step_5 = pd.DataFrame(topic_probabilities.iloc[16499:23888, :].sum()/7389).T\n",
    "    step_6 = pd.DataFrame(topic_probabilities.iloc[23888:29859, :].sum()/5971).T\n",
    "    step_7 = pd.DataFrame(topic_probabilities.iloc[29859:37816, :].sum()/7957).T\n",
    "    step_8 = pd.DataFrame(topic_probabilities.iloc[37816:44674, :].sum()/6858).T\n",
    "    step_9 = pd.DataFrame(topic_probabilities.iloc[44674:48617, :].sum()/3943).T\n",
    "    step_10 = pd.DataFrame(topic_probabilities.iloc[48617:58073, :].sum()/9456).T\n",
    "    step_11 = pd.DataFrame(topic_probabilities.iloc[58073:67408, :].sum()/9335).T\n",
    "    step_12 = pd.DataFrame(topic_probabilities.iloc[67408:77520, :].sum()/10112).T\n",
    "    step_13 = pd.DataFrame(topic_probabilities.iloc[77520:87945, :].sum()/10452).T\n",
    "    step_14 = pd.DataFrame(topic_probabilities.iloc[87945:98976, :].sum()/11031).T\n",
    "    step_15 = pd.DataFrame(topic_probabilities.iloc[98976:106746, :].sum()/7770).T\n",
    "    step_16 = pd.DataFrame(topic_probabilities.iloc[106746:119131, :].sum()/12385).T\n",
    "    step_17 = pd.DataFrame(topic_probabilities.iloc[119131:135905, :].sum()/16774).T\n",
    "    step_18 = pd.DataFrame(topic_probabilities.iloc[135905:148132, :].sum()/12227).T\n",
    "    step_19 = pd.DataFrame(topic_probabilities.iloc[148132:164869, :].sum()/16737).T\n",
    "    time_steps = [step_1,step_2,step_3,step_4,step_5,step_6,step_7,step_8,step_9,step_10,step_11,step_12,step_13,step_14,step_15,step_16,step_17,step_18,step_19]\n",
    "    topic_distribution_total= pd.concat(time_steps)\n",
    "    topic_distribution_total.index = ['1. Term','2. Term','3. Term','4. Term','5. Term','6. Term','7. Term','8. Term', '9. Term',\n",
    "                  '10. Term', '11. Term', '12. Term', '13. Term', '14. Term', '15. Term', '16. Term','17. Term',\n",
    "                  '18. Term', '19. Term']\n",
    "    topic_distribution_total.columns = ['Term','Topic 0','Topic 1','Topic 2','Topic 3','Topic 4','Topic 5','Topic 6','Topic 7','Topic 8','Topic 9','Topic 10', 'Topic 11','Topic 12','Topic 13','Topic 14','Topic 15','Topic 16','Topic 17','Topic 18', 'Topic 19','Topic 20','Topic 21','Topic 22','Topic 23', 'Topic 24','Topic 25','Topic 26','Topic 27','Topic 28','Topic 29','Topic 30']\n",
    "    return topic_distribution_total\n",
    "\n",
    "topic_probabilities_over_time_steps = get_topic_probabilities_over_time_steps(topic_probabilities=topic_probabilities_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_topic_probability_over_time(data, number_of_plots, result_path=None, title=None):\n",
    "    '''\n",
    "\n",
    "    :param data: dataframe containing the topic probabilities for documents in a corpus\n",
    "    :param number_of_plots: number of topics that should be plotted\n",
    "    :param result_path: path for saving the plot to disk (optional)\n",
    "    :param title: title of the plot (optional)\n",
    "    :return: A figure that displays the share of topics over all elecotral Terms as a line plot\n",
    "    '''\n",
    "    #define color palette for multiplot\n",
    "    colors = sns.color_palette(cc.glasbey_light, number_of_plots)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    #set general fontsize\n",
    "    plt.rcParams['font.size'] = '16'\n",
    "    #fontsize for ticks\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(14)\n",
    "\n",
    "    data.plot(kind=\"line\", color=colors,linewidth=4.0,figsize=(20, 10),ax=ax)\n",
    "    #data.plot(kind=\"line\", y=\"Topic 14\", color='palegoldenrod',linewidth=7.0,figsize=(20, 10),ax=ax)\n",
    "    #data.plot(kind=\"line\", y=\"Topic 28\", color='deeppink',linewidth=7.0,figsize=(20, 10),ax=ax)\n",
    "    #data.plot(kind=\"line\", y=\"Topic 30\", color='lightslategrey',linewidth=7.0,figsize=(20, 10), ax=ax)\n",
    "    #data.plot(kind=\"line\", y=\"Topic 18\", color='plum', linewidth=7.0, figsize=(20, 10), ax=ax)\n",
    "    #data.plot(kind=\"line\", y=\"Topic 25\", color='darkolivegreen', linewidth=7.0, figsize=(20, 10), ax=ax)\n",
    "\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    ax.set_ylabel('Topic Probability')\n",
    "    ax.set_xlabel('Electoral Terms')\n",
    "    ax.set_xticks(np.arange(0, 19, 1))\n",
    "\n",
    "    fig = ax.get_figure()\n",
    "    if result_path:\n",
    "        fig.savefig(os.path.join(result_path, 'topic_probability_over_time',title))\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "plot_topic_probability_over_time(data=topic_probabilities_over_time_steps, number_of_plots=31, result_path=result_path, title='LDA_topic_probability_over_time.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_coherence_num_topics_random(data,result_path=None,title=None):\n",
    "    '''\n",
    "\n",
    "    :param data: dataframe with the results from the gridsearch performed to identify the optimal combination of num_topics and random_state\n",
    "    :return: Plots Topics on x and Coherence on y axis, while the hue indicates the Random_State used at a particular run\n",
    "    '''\n",
    "    ax = sns.catplot(data=data, x='Topics', y='Coherence', hue='Random_State', kind='point')\n",
    "    ax.fig.set_figwidth(16)\n",
    "    ax.fig.set_figheight(6)\n",
    "    fig = ax.fig\n",
    "    fig.show()\n",
    "    if result_path:\n",
    "        fig.savefig(os.path.join(result_path, 'topic_search_results',title))\n",
    "\n",
    "    return fig\n",
    "\n",
    "plot_coherence_num_topics_random(data=results_num_topics_comparison)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}