{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "#BERTopic related imports\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "import hdbscan\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "#gensim imports\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "#sklean imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#visual imports\n",
    "import seaborn as sns\n",
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting paths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir(\"../..\")\n",
    "data_path = os.path.join(os.path.abspath(os.curdir), 'corpus','preprocessed')\n",
    "result_path = os.path.join(os.path.abspath(os.curdir),'models','BERTopic')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading pre-processed data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = os.path.join(data_path,'electoralTerms', 'BERTopic_time_steps.pkl')\n",
    "with open(file_name, 'rb') as pickle_file:\n",
    "    speeches = pickle.load(pickle_file)\n",
    "\n",
    "file_name = os.path.join(data_path,'corpus', 'BERTopic_corpus_preprocessed.pkl')\n",
    "with open(file_name, 'rb') as pickle_file:\n",
    "    time_steps = pickle.load(pickle_file)\n",
    "\n",
    "file_name = os.path.join(result_path,'model_results', 'topics_over_time.pkl')\n",
    "with open(file_name, 'rb') as pickle_file:\n",
    "    topics_over_time = pickle.load(pickle_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading trained BERTopic model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_path = os.path.join(result_path, 'model_results', 'BERTopic')\n",
    "topic_model = BERTopic.load(model_path)\n",
    "\n",
    "# re-calculate topics and probabilities as these are not saved along with the model to save diskspace\n",
    "topics= topic_model._map_predictions(topic_model.hdbscan_model.labels_)\n",
    "\n",
    "probs = hdbscan.all_points_membership_vectors(topic_model.hdbscan_model)\n",
    "probs = topic_model._map_probabilities(probs, original_topics=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating topic coherence and topic diversity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract vectorizer and tokenizer from BERTopic\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "# Extract features for topic coherence evaluation\n",
    "words = vectorizer.get_feature_names()\n",
    "tokens = [tokenizer(doc) for doc in speeches]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] for topic in range(len(set(topics))-1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coherence_model = CoherenceModel(topics=topic_words,\n",
    "                                 texts=tokens,\n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary,\n",
    "                                 coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()\n",
    "print(coherence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_list_of_topics (dataframe,time_step):\n",
    "  '''\n",
    "\n",
    "  :param dataframe: dataframe containing all topics for all time steps\n",
    "  :param time: a specific time step a list of topics is to be returned for\n",
    "  :return: list of list containing the top words associated with each topic at a given time step. Repeat for all time stes\n",
    "  '''\n",
    "  dataframe.drop(dataframe[dataframe['Topic'] == -1].index, inplace = True)\n",
    "  topics_at_time = dataframe.loc[dataframe[\"Timestamp\"] == time_step,\"Words\"]\n",
    "  word_list = pd.DataFrame(topics_at_time)\n",
    "  word_list_of_list = word_list.values.tolist()\n",
    "  list_of_topics = [[word for line in sub_list for word in line.split()] for sub_list in word_list_of_list]\n",
    "  return list_of_topics\n",
    "\n",
    "topic_list = get_list_of_topics (dataframe=topics_over_time,time_step=19)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_topic_diversity(topics,topn):\n",
    "    '''\n",
    "\n",
    "    :param topics: list of list of topics as strings\n",
    "    :param topn: number of top words used to compute topic divcersity\n",
    "    :return:  topic diversity score as proportion of unique words for a specific time step. Repeat for all time steps\n",
    "    and average score.\n",
    "    '''\n",
    "    if topn > len(topics[0]):\n",
    "        raise Exception('not enough words for topn ' + str(topn))\n",
    "    else:\n",
    "        unique_words = set()\n",
    "        for topic in topics:\n",
    "            unique_words = unique_words.union(set(topic[:topn]))\n",
    "        td = len(unique_words) / (topn * len(topics))\n",
    "        return td\n",
    "print('Topic diversity: ', get_topic_diversity(topics=topic_list, topn=25))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Further analysis of the model results and creation of plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print static topic representations\n",
    "topic_model.get_topics()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create a dataframe that contains the consolidated topic probabilities along time steps\n",
    "topic_probabilities = pd.DataFrame(data=probs, index=None, columns=[\"Topic 0\",\"Topic 1\",\"Topic 2\",\"Topic 3\",\"Topic 4\",\"Topic 5\",\"Topic 6\",\"Topic 7\",\"Topic 8\",\"Topic 9\",\"Topic 10\",\"Topic 11\",\"Topic 12\",\"Topic 13\",\"Topic 14\",\"Topic_15\",\"Topic 16\",\"Topic 17\",\"Topic 18\",\"Topic 19\",\"Topic 20\",\"Topic_21\",\"Topic 22\",\"Topic 23\",\"Topic 24\",\"Topic 25\",\"Topic 26\",\"Topic 27\",\"Topic 28\",\"Topic 29\",\"Topic 30\"])\n",
    "\n",
    "step_1 = pd.DataFrame(topic_probabilities.iloc[0:4444, :].sum()/4444).T\n",
    "step_2 = pd.DataFrame(topic_probabilities.iloc[4444:8079, :].sum()/3635).T\n",
    "step_3 = pd.DataFrame(topic_probabilities.iloc[8079:11335, :].sum()/3256).T\n",
    "step_4 = pd.DataFrame(topic_probabilities.iloc[11335:16499, :].sum()/5164).T\n",
    "step_5 = pd.DataFrame(topic_probabilities.iloc[16499:23888, :].sum()/7389).T\n",
    "step_6 = pd.DataFrame(topic_probabilities.iloc[23888:29859, :].sum()/5971).T\n",
    "step_7 = pd.DataFrame(topic_probabilities.iloc[29859:37816, :].sum()/7957).T\n",
    "step_8 = pd.DataFrame(topic_probabilities.iloc[37816:44674, :].sum()/6858).T\n",
    "step_9 = pd.DataFrame(topic_probabilities.iloc[44674:48617, :].sum()/3943).T\n",
    "step_10 = pd.DataFrame(topic_probabilities.iloc[48617:58073, :].sum()/9456).T\n",
    "step_11 = pd.DataFrame(topic_probabilities.iloc[58073:67408, :].sum()/9335).T\n",
    "step_12 = pd.DataFrame(topic_probabilities.iloc[67408:77520, :].sum()/10112).T\n",
    "step_13 = pd.DataFrame(topic_probabilities.iloc[77520:87945, :].sum()/10452).T\n",
    "step_14 = pd.DataFrame(topic_probabilities.iloc[87945:98976, :].sum()/11031).T\n",
    "step_15 = pd.DataFrame(topic_probabilities.iloc[98976:106746, :].sum()/7770).T\n",
    "step_16 = pd.DataFrame(topic_probabilities.iloc[106746:119131, :].sum()/12385).T\n",
    "step_17 = pd.DataFrame(topic_probabilities.iloc[119131:135905, :].sum()/16774).T\n",
    "step_18 = pd.DataFrame(topic_probabilities.iloc[135905:148132, :].sum()/12227).T\n",
    "step_19 = pd.DataFrame(topic_probabilities.iloc[148132:164869, :].sum()/16737).T\n",
    "\n",
    "time_steps = [step_1,step_2,step_3,step_4,step_5,step_6,step_7,step_8,step_9,step_10,step_11,step_12,step_13,step_14,step_15,step_16,step_17,step_18,step_19]\n",
    "\n",
    "topic_probabilities_over_time_steps= pd.concat(time_steps)\n",
    "\n",
    "topic_probabilities_over_time_steps.index = ['1. Term','2. Term','3. Term','4. Term','5. Term','6. Term','7. Term','8. Term', '9. Term',\n",
    "                  '10. Term', '11. Term', '12. Term', '13. Term', '14. Term', '15. Term', '16. Term','17. Term',\n",
    "                  '18. Term', '19. Term']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_topic_probability_over_time(data, number_of_plots, result_path=None, title=None):\n",
    "    '''\n",
    "\n",
    "    :param data: dataframe containing the topic probabilities for documents in a corpus\n",
    "    :param number_of_plots: number of topics that should be plotted\n",
    "    :param result_path: path for saving the plot to disk (optional)\n",
    "    :param title: title of the plot (optional)\n",
    "    :return: A figure that displays the share of topics over all elecotral Terms as a line plot\n",
    "    '''\n",
    "    #define color palette for multiplot\n",
    "    colors = sns.color_palette(cc.glasbey_light, number_of_plots)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    #set general fontsize\n",
    "    plt.rcParams['font.size'] = '16'\n",
    "    #fontsize for ticks\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(14)\n",
    "\n",
    "\n",
    "    data.plot(kind=\"line\", y=\"Topic 15\", color='sienna',linewidth=7.0,figsize=(20, 10),ax=ax)\n",
    "    data.plot(kind=\"line\", y=\"Topic 17\", color='lime',linewidth=7.0,figsize=(20, 10),ax=ax)\n",
    "    data.plot(kind=\"line\", y=\"Topic 22\", color='orange', linewidth=7.0, figsize=(20, 10), ax=ax)\n",
    "    data.plot(kind=\"line\", y=\"Topic 23\", color='lightseagreen',linewidth=7.0,figsize=(20, 10), ax=ax)\n",
    "    # data.plot(kind=\"line\", y=\"Topic 18\", color='plum', linewidth=7.0, figsize=(20, 10), ax=ax)\n",
    "    # data.plot(kind=\"line\", y=\"Topic 25\", color='darkolivegreen', linewidth=7.0, figsize=(20, 10), ax=ax)\n",
    "\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    ax.set_ylabel('Topic Probability')\n",
    "    ax.set_xlabel('Electoral Terms')\n",
    "    ax.set_xticks(np.arange(0, 19, 1))\n",
    "\n",
    "    fig = ax.get_figure()\n",
    "    if result_path:\n",
    "        fig.savefig(os.path.join(result_path, 'topic_probability_over_time',title))\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "plot_topic_probability_over_time(data=topic_probabilities_over_time_steps, number_of_plots=31, result_path=result_path, title='BERTopic_topic_probability_over_time_topic_15_17_22_23.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}